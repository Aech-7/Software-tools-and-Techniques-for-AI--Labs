{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aech-7/Software-tools-and-Techniques-for-AI--Labs/blob/main/labs/week01-data-collection-lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx9-gQXNfXhP"
      },
      "source": [
        "# Week 1 Lab: Data Collection for Machine Learning\n",
        "\n",
        "**CS 203: Software Tools and Techniques for AI**\n",
        "\n",
        "---\n",
        "\n",
        "## Lab Overview\n",
        "\n",
        "In this lab, you will learn to collect data from the web using:\n",
        "\n",
        "1. **HTTP fundamentals** - Understanding how the web works\n",
        "2. **curl** - Command-line HTTP client\n",
        "3. **Python requests** - Programmatic API calls\n",
        "4. **BeautifulSoup** - Web scraping when APIs don't exist\n",
        "\n",
        "**Goal**: Build a movie data collection pipeline for Netflix-style movie prediction.\n",
        "\n",
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's install and import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6F2hful9fXhT"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qGAOBFnifXhW",
        "outputId": "2feaa3d1-d4d3-4b80-a98f-b58c3d78b5b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhEk-Ig7fXhX"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: HTTP Fundamentals\n",
        "\n",
        "Before we start collecting data, we need to understand how the web works.\n",
        "\n",
        "## 1.1 Understanding URLs\n",
        "\n",
        "A URL (Uniform Resource Locator) has several components:\n",
        "\n",
        "```\n",
        "https://api.omdbapi.com:443/v1/movies?t=Inception&y=2010#details\n",
        "└─┬──┘ └──────┬───────┘└┬─┘└───┬───┘└─────────┬────────┘└───┬───┘\n",
        "  │           │         │      │              │             │\n",
        "Protocol    Host      Port   Path          Query        Fragment\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KILvT1W4fXhZ"
      },
      "source": [
        "### Question 1.1 (Solved): Parse a URL\n",
        "\n",
        "Use Python's `urllib.parse` to break down a URL into its components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ABNhT14fXha",
        "outputId": "c4e6f3da-847c-4dd1-c65b-0a6502d16bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheme (protocol): https\n",
            "Host (domain): api.omdbapi.com\n",
            "Path: /\n",
            "Query string: apikey=demo&t=Inception&y=2010\n",
            "\n",
            "Parsed parameters: {'apikey': ['demo'], 't': ['Inception'], 'y': ['2010']}\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "url = \"https://api.omdbapi.com/?apikey=demo&t=Inception&y=2010\"\n",
        "\n",
        "parsed = urlparse(url)\n",
        "\n",
        "print(f\"Scheme (protocol): {parsed.scheme}\")\n",
        "print(f\"Host (domain): {parsed.netloc}\")\n",
        "print(f\"Path: {parsed.path}\")\n",
        "print(f\"Query string: {parsed.query}\")\n",
        "\n",
        "# Parse query parameters into a dictionary\n",
        "params = parse_qs(parsed.query)\n",
        "print(f\"\\nParsed parameters: {params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSJ1cWJZfXhb"
      },
      "source": [
        "### Question 1.2: Parse a Different URL\n",
        "\n",
        "Parse the following GitHub API URL and extract:\n",
        "1. The host\n",
        "2. The path\n",
        "3. All query parameters as a dictionary\n",
        "\n",
        "URL: `https://api.github.com/search/repositories?q=machine+learning&sort=stars&order=desc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QNv7u7cifXhc",
        "outputId": "d0fb5f40-ef83-4a68-a39e-6791474fa135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Host : api.github.com\n",
            "path: /search/repositories\n",
            "Query : {'q': ['machine learning'], 'sort': ['stars'], 'order': ['desc']}\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "url = \"https://api.github.com/search/repositories?q=machine+learning&sort=stars&order=desc\"\n",
        "\n",
        "# Parse the URL\n",
        "urlparse = urlparse(url)\n",
        "\n",
        "# Print the host\n",
        "print(f\"Host : {urlparse.netloc}\")\n",
        "\n",
        "# Print the path\n",
        "print(f\"path: {urlparse.path}\")\n",
        "\n",
        "# Print the query parameters as a dictionary\n",
        "print(f\"Query : {parse_qs(urlparse.query)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkK3JbmNfXhd"
      },
      "source": [
        "---\n",
        "\n",
        "## 1.2 HTTP Status Codes\n",
        "\n",
        "HTTP status codes tell you what happened with your request:\n",
        "\n",
        "| Range | Category | Common Examples |\n",
        "|-------|----------|----------------|\n",
        "| 2xx | Success | 200 OK, 201 Created |\n",
        "| 3xx | Redirect | 301 Moved, 302 Found |\n",
        "| 4xx | Client Error | 400 Bad Request, 401 Unauthorized, 404 Not Found |\n",
        "| 5xx | Server Error | 500 Internal Error, 503 Service Unavailable |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2hd9RJ_fXhe"
      },
      "source": [
        "### Question 1.3: Match Status Codes\n",
        "\n",
        "Match each scenario to the most likely HTTP status code:\n",
        "\n",
        "1. You requested a movie that doesn't exist in the database\n",
        "2. You made too many requests and hit the rate limit\n",
        "3. Your API key is invalid\n",
        "4. The request was successful and data was returned\n",
        "5. The server crashed while processing your request\n",
        "\n",
        "Status codes to choose from: `200`, `401`, `404`, `429`, `500`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GAHNRIiZfXhe",
        "outputId": "0694e20f-c0ae-4738-92f9-afd44a8ba5c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie_not_found': 404, 'rate_limited': 429, 'invalid_api_key': 401, 'success': 200, 'server_crashed': 500}\n"
          ]
        }
      ],
      "source": [
        "# YOUR ANSWERS HERE\n",
        "answers = {\n",
        "    \"movie_not_found\": 404,      # Replace None with the status code\n",
        "    \"rate_limited\": 429,\n",
        "    \"invalid_api_key\": 401,\n",
        "    \"success\": 200,\n",
        "    \"server_crashed\": 500\n",
        "}\n",
        "\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v8-3pFqfXhf"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: Making Requests with `curl`\n",
        "\n",
        "`curl` is a command-line tool for making HTTP requests. It's essential for quick testing.\n",
        "\n",
        "## 2.1 Basic curl Commands\n",
        "\n",
        "You can run shell commands in Jupyter using `!` prefix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-W8-ZnafXhf"
      },
      "source": [
        "### Question 2.1 (Solved): Your First API Call\n",
        "\n",
        "Let's call a simple public API that requires no authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kGpBBD02fXhg",
        "outputId": "3d7dda61-97a5-4a2f-93cb-0bbcecd039df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"userId\": 1,\n",
            "  \"id\": 1,\n",
            "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
            "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
            "}"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "# JSONPlaceholder is a free fake API for testing\n",
        "!curl -s \"https://jsonplaceholder.typicode.com/posts/1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHo21ox_fXhh"
      },
      "source": [
        "### Question 2.2: Pretty Print with jq\n",
        "\n",
        "The output above is hard to read. Use `jq` to format it nicely.\n",
        "\n",
        "**Hint**: Pipe the curl output to jq: `curl ... | jq .`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-edT-G6tfXhh",
        "outputId": "fad29192-6bba-487f-89ba-6b9d8a96d50f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;39m{\n",
            "  \u001b[0m\u001b[34;1m\"userId\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"body\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\u001b[0m\u001b[1;39m\n",
            "\u001b[1;39m}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Fetch the same post but format the output with jq\n",
        "\n",
        "!curl -s \"https://jsonplaceholder.typicode.com/posts/1\" | jq .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF514VYSfXhh"
      },
      "source": [
        "### Question 2.3: Extract Specific Fields with jq\n",
        "\n",
        "Fetch all posts from `https://jsonplaceholder.typicode.com/posts` and extract only the `title` field from each post.\n",
        "\n",
        "**Hint**: Use `jq '.[].title'` to get the title from each element in the array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "asbYIeETfXhh",
        "outputId": "aabce605-f34f-464c-fc3a-eca84c40f7b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;32m\"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\"\u001b[0m\n",
            "\u001b[0;32m\"qui est esse\"\u001b[0m\n",
            "\u001b[0;32m\"ea molestias quasi exercitationem repellat qui ipsa sit aut\"\u001b[0m\n",
            "\u001b[0;32m\"eum et est occaecati\"\u001b[0m\n",
            "\u001b[0;32m\"nesciunt quas odio\"\u001b[0m\n",
            "\u001b[0;32m\"dolorem eum magni eos aperiam quia\"\u001b[0m\n",
            "\u001b[0;32m\"magnam facilis autem\"\u001b[0m\n",
            "\u001b[0;32m\"dolorem dolore est ipsam\"\u001b[0m\n",
            "\u001b[0;32m\"nesciunt iure omnis dolorem tempora et accusantium\"\u001b[0m\n",
            "\u001b[0;32m\"optio molestias id quia eum\"\u001b[0m\n",
            "\u001b[0;32m\"et ea vero quia laudantium autem\"\u001b[0m\n",
            "\u001b[0;32m\"in quibusdam tempore odit est dolorem\"\u001b[0m\n",
            "\u001b[0;32m\"dolorum ut in voluptas mollitia et saepe quo animi\"\u001b[0m\n",
            "\u001b[0;32m\"voluptatem eligendi optio\"\u001b[0m\n",
            "\u001b[0;32m\"eveniet quod temporibus\"\u001b[0m\n",
            "\u001b[0;32m\"sint suscipit perspiciatis velit dolorum rerum ipsa laboriosam odio\"\u001b[0m\n",
            "\u001b[0;32m\"fugit voluptas sed molestias voluptatem provident\"\u001b[0m\n",
            "\u001b[0;32m\"voluptate et itaque vero tempora molestiae\"\u001b[0m\n",
            "\u001b[0;32m\"adipisci placeat illum aut reiciendis qui\"\u001b[0m\n",
            "\u001b[0;32m\"doloribus ad provident suscipit at\"\u001b[0m\n",
            "\u001b[0;32m\"asperiores ea ipsam voluptatibus modi minima quia sint\"\u001b[0m\n",
            "\u001b[0;32m\"dolor sint quo a velit explicabo quia nam\"\u001b[0m\n",
            "\u001b[0;32m\"maxime id vitae nihil numquam\"\u001b[0m\n",
            "\u001b[0;32m\"autem hic labore sunt dolores incidunt\"\u001b[0m\n",
            "\u001b[0;32m\"rem alias distinctio quo quis\"\u001b[0m\n",
            "\u001b[0;32m\"est et quae odit qui non\"\u001b[0m\n",
            "\u001b[0;32m\"quasi id et eos tenetur aut quo autem\"\u001b[0m\n",
            "\u001b[0;32m\"delectus ullam et corporis nulla voluptas sequi\"\u001b[0m\n",
            "\u001b[0;32m\"iusto eius quod necessitatibus culpa ea\"\u001b[0m\n",
            "\u001b[0;32m\"a quo magni similique perferendis\"\u001b[0m\n",
            "\u001b[0;32m\"ullam ut quidem id aut vel consequuntur\"\u001b[0m\n",
            "\u001b[0;32m\"doloremque illum aliquid sunt\"\u001b[0m\n",
            "\u001b[0;32m\"qui explicabo molestiae dolorem\"\u001b[0m\n",
            "\u001b[0;32m\"magnam ut rerum iure\"\u001b[0m\n",
            "\u001b[0;32m\"id nihil consequatur molestias animi provident\"\u001b[0m\n",
            "\u001b[0;32m\"fuga nam accusamus voluptas reiciendis itaque\"\u001b[0m\n",
            "\u001b[0;32m\"provident vel ut sit ratione est\"\u001b[0m\n",
            "\u001b[0;32m\"explicabo et eos deleniti nostrum ab id repellendus\"\u001b[0m\n",
            "\u001b[0;32m\"eos dolorem iste accusantium est eaque quam\"\u001b[0m\n",
            "\u001b[0;32m\"enim quo cumque\"\u001b[0m\n",
            "\u001b[0;32m\"non est facere\"\u001b[0m\n",
            "\u001b[0;32m\"commodi ullam sint et excepturi error explicabo praesentium voluptas\"\u001b[0m\n",
            "\u001b[0;32m\"eligendi iste nostrum consequuntur adipisci praesentium sit beatae perferendis\"\u001b[0m\n",
            "\u001b[0;32m\"optio dolor molestias sit\"\u001b[0m\n",
            "\u001b[0;32m\"ut numquam possimus omnis eius suscipit laudantium iure\"\u001b[0m\n",
            "\u001b[0;32m\"aut quo modi neque nostrum ducimus\"\u001b[0m\n",
            "\u001b[0;32m\"quibusdam cumque rem aut deserunt\"\u001b[0m\n",
            "\u001b[0;32m\"ut voluptatem illum ea doloribus itaque eos\"\u001b[0m\n",
            "\u001b[0;32m\"laborum non sunt aut ut assumenda perspiciatis voluptas\"\u001b[0m\n",
            "\u001b[0;32m\"repellendus qui recusandae incidunt voluptates tenetur qui omnis exercitationem\"\u001b[0m\n",
            "\u001b[0;32m\"soluta aliquam aperiam consequatur illo quis voluptas\"\u001b[0m\n",
            "\u001b[0;32m\"qui enim et consequuntur quia animi quis voluptate quibusdam\"\u001b[0m\n",
            "\u001b[0;32m\"ut quo aut ducimus alias\"\u001b[0m\n",
            "\u001b[0;32m\"sit asperiores ipsam eveniet odio non quia\"\u001b[0m\n",
            "\u001b[0;32m\"sit vel voluptatem et non libero\"\u001b[0m\n",
            "\u001b[0;32m\"qui et at rerum necessitatibus\"\u001b[0m\n",
            "\u001b[0;32m\"sed ab est est\"\u001b[0m\n",
            "\u001b[0;32m\"voluptatum itaque dolores nisi et quasi\"\u001b[0m\n",
            "\u001b[0;32m\"qui commodi dolor at maiores et quis id accusantium\"\u001b[0m\n",
            "\u001b[0;32m\"consequatur placeat omnis quisquam quia reprehenderit fugit veritatis facere\"\u001b[0m\n",
            "\u001b[0;32m\"voluptatem doloribus consectetur est ut ducimus\"\u001b[0m\n",
            "\u001b[0;32m\"beatae enim quia vel\"\u001b[0m\n",
            "\u001b[0;32m\"voluptas blanditiis repellendus animi ducimus error sapiente et suscipit\"\u001b[0m\n",
            "\u001b[0;32m\"et fugit quas eum in in aperiam quod\"\u001b[0m\n",
            "\u001b[0;32m\"consequatur id enim sunt et et\"\u001b[0m\n",
            "\u001b[0;32m\"repudiandae ea animi iusto\"\u001b[0m\n",
            "\u001b[0;32m\"aliquid eos sed fuga est maxime repellendus\"\u001b[0m\n",
            "\u001b[0;32m\"odio quis facere architecto reiciendis optio\"\u001b[0m\n",
            "\u001b[0;32m\"fugiat quod pariatur odit minima\"\u001b[0m\n",
            "\u001b[0;32m\"voluptatem laborum magni\"\u001b[0m\n",
            "\u001b[0;32m\"et iusto veniam et illum aut fuga\"\u001b[0m\n",
            "\u001b[0;32m\"sint hic doloribus consequatur eos non id\"\u001b[0m\n",
            "\u001b[0;32m\"consequuntur deleniti eos quia temporibus ab aliquid at\"\u001b[0m\n",
            "\u001b[0;32m\"enim unde ratione doloribus quas enim ut sit sapiente\"\u001b[0m\n",
            "\u001b[0;32m\"dignissimos eum dolor ut enim et delectus in\"\u001b[0m\n",
            "\u001b[0;32m\"doloremque officiis ad et non perferendis\"\u001b[0m\n",
            "\u001b[0;32m\"necessitatibus quasi exercitationem odio\"\u001b[0m\n",
            "\u001b[0;32m\"quam voluptatibus rerum veritatis\"\u001b[0m\n",
            "\u001b[0;32m\"pariatur consequatur quia magnam autem omnis non amet\"\u001b[0m\n",
            "\u001b[0;32m\"labore in ex et explicabo corporis aut quas\"\u001b[0m\n",
            "\u001b[0;32m\"tempora rem veritatis voluptas quo dolores vero\"\u001b[0m\n",
            "\u001b[0;32m\"laudantium voluptate suscipit sunt enim enim\"\u001b[0m\n",
            "\u001b[0;32m\"odit et voluptates doloribus alias odio et\"\u001b[0m\n",
            "\u001b[0;32m\"optio ipsam molestias necessitatibus occaecati facilis veritatis dolores aut\"\u001b[0m\n",
            "\u001b[0;32m\"dolore veritatis porro provident adipisci blanditiis et sunt\"\u001b[0m\n",
            "\u001b[0;32m\"placeat quia et porro iste\"\u001b[0m\n",
            "\u001b[0;32m\"nostrum quis quasi placeat\"\u001b[0m\n",
            "\u001b[0;32m\"sapiente omnis fugit eos\"\u001b[0m\n",
            "\u001b[0;32m\"sint soluta et vel magnam aut ut sed qui\"\u001b[0m\n",
            "\u001b[0;32m\"ad iusto omnis odit dolor voluptatibus\"\u001b[0m\n",
            "\u001b[0;32m\"aut amet sed\"\u001b[0m\n",
            "\u001b[0;32m\"ratione ex tenetur perferendis\"\u001b[0m\n",
            "\u001b[0;32m\"beatae soluta recusandae\"\u001b[0m\n",
            "\u001b[0;32m\"qui qui voluptates illo iste minima\"\u001b[0m\n",
            "\u001b[0;32m\"id minus libero illum nam ad officiis\"\u001b[0m\n",
            "\u001b[0;32m\"quaerat velit veniam amet cupiditate aut numquam ut sequi\"\u001b[0m\n",
            "\u001b[0;32m\"quas fugiat ut perspiciatis vero provident\"\u001b[0m\n",
            "\u001b[0;32m\"laboriosam dolor voluptates\"\u001b[0m\n",
            "\u001b[0;32m\"temporibus sit alias delectus eligendi possimus magni\"\u001b[0m\n",
            "\u001b[0;32m\"at nam consequatur ea labore ea harum\"\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "!curl -s \"https://jsonplaceholder.typicode.com/posts\" | jq '.[].title'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmihnWHwfXhi"
      },
      "source": [
        "### Question 2.4: View Response Headers\n",
        "\n",
        "Use the `-I` flag to fetch only the response headers (no body) from:\n",
        "`https://api.github.com`\n",
        "\n",
        "What is the value of the `X-RateLimit-Limit` header?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DwAAwED9fXhi",
        "outputId": "47154b04-8e3a-469f-ca49-e95d3cdb0c6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP/2 200 \r\n",
            "\u001b[1mdate\u001b[0m: Thu, 29 Jan 2026 18:57:49 GMT\r\n",
            "\u001b[1mcontent-type\u001b[0m: application/json; charset=utf-8\r\n",
            "\u001b[1mcontent-length\u001b[0m: 292\r\n",
            "\u001b[1maccess-control-allow-credentials\u001b[0m: true\r\n",
            "\u001b[1mcache-control\u001b[0m: max-age=43200\r\n",
            "\u001b[1metag\u001b[0m: W/\"124-yiKdLzqO5gfBrJFrcdJ8Yq0LGnU\"\r\n",
            "\u001b[1mexpires\u001b[0m: -1\r\n",
            "\u001b[1mnel\u001b[0m: {\"report_to\":\"heroku-nel\",\"response_headers\":[\"Via\"],\"max_age\":3600,\"success_fraction\":0.01,\"failure_fraction\":0.1}\r\n",
            "\u001b[1mpragma\u001b[0m: no-cache\r\n",
            "\u001b[1mreport-to\u001b[0m: {\"group\":\"heroku-nel\",\"endpoints\":[{\"url\":\"https://nel.heroku.com/reports?s=fYWdnEf0DmCzgr0VsN5e6AtGFTukaisQ17mn0sPpnh8%3D\\u0026sid=e11707d5-02a7-43ef-b45e-2cf4d2036f7d\\u0026ts=1769696362\"}],\"max_age\":3600}\r\n",
            "\u001b[1mreporting-endpoints\u001b[0m: heroku-nel=\"https://nel.heroku.com/reports?s=fYWdnEf0DmCzgr0VsN5e6AtGFTukaisQ17mn0sPpnh8%3D&sid=e11707d5-02a7-43ef-b45e-2cf4d2036f7d&ts=1769696362\"\r\n",
            "\u001b[1mserver\u001b[0m: cloudflare\r\n",
            "\u001b[1mvary\u001b[0m: Origin, Accept-Encoding\r\n",
            "\u001b[1mvia\u001b[0m: 2.0 heroku-router\r\n",
            "\u001b[1mx-content-type-options\u001b[0m: nosniff\r\n",
            "\u001b[1mx-powered-by\u001b[0m: Express\r\n",
            "\u001b[1mx-ratelimit-limit\u001b[0m: 1000\r\n",
            "\u001b[1mx-ratelimit-remaining\u001b[0m: 999\r\n",
            "\u001b[1mx-ratelimit-reset\u001b[0m: 1769696416\r\n",
            "\u001b[1mage\u001b[0m: 16707\r\n",
            "\u001b[1maccept-ranges\u001b[0m: bytes\r\n",
            "\u001b[1mcf-cache-status\u001b[0m: HIT\r\n",
            "\u001b[1mcf-ray\u001b[0m: 9c5af51d8d568356-SIN\r\n",
            "\u001b[1malt-svc\u001b[0m: h3=\":443\"; ma=86400\r\n",
            "\r\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "!curl -I \"https://jsonplaceholder.typicode.com/posts/1\" | grep -i x-ratelimit-limit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P99uY2uVfXhi"
      },
      "source": [
        "### Question 2.5: Add Custom Headers\n",
        "\n",
        "Make a request to `https://httpbin.org/headers` with the following custom headers:\n",
        "- `User-Agent: CS203-Lab/1.0`\n",
        "- `Accept: application/json`\n",
        "\n",
        "**Hint**: Use `-H \"Header-Name: value\"` for each header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SwHSbootfXhi",
        "outputId": "609a5484-9d61-48b1-ec68-589fcb89cbf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"headers\": {\n",
            "    \"Accept\": \"application/json\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"CS203-Lab/1.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-697baecf-1e438227341653635e4db11f\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "!curl -H 'User-Agent: CS203-Lab/1.0' -H 'Accept: application/json' 'https://httpbin.org/headers'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWlc2lsMfXhi"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: Python `requests` Library\n",
        "\n",
        "While `curl` is great for testing, we need Python for automation.\n",
        "\n",
        "## 3.1 Basic GET Requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHJOZZyHfXhj"
      },
      "source": [
        "### Question 3.1 (Solved): Simple GET Request\n",
        "\n",
        "Make a GET request and inspect the response object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "f-E-ttkwfXhj",
        "outputId": "7acfdcfb-217d-4738-a6a8-8b59026708ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Content-Type: application/json; charset=utf-8\n",
            "Response OK: True\n",
            "\n",
            "JSON Data:\n",
            "{'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")\n",
        "print(f\"Content-Type: {response.headers['Content-Type']}\")\n",
        "print(f\"Response OK: {response.ok}\")\n",
        "print(f\"\\nJSON Data:\")\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLWJa9pMfXhj"
      },
      "source": [
        "### Question 3.2: Fetch Multiple Posts\n",
        "\n",
        "Fetch posts from `https://jsonplaceholder.typicode.com/posts` and:\n",
        "1. Print the total number of posts\n",
        "2. Print the titles of the first 5 posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CrSuI8DyfXhj",
        "outputId": "fc252a61-fc3d-4963-956b-62dbf3d7b1a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No of posts : 100\n",
            "Title : sunt aut facere repellat provident occaecati excepturi optio reprehenderit\n",
            "Title : qui est esse\n",
            "Title : ea molestias quasi exercitationem repellat qui ipsa sit aut\n",
            "Title : eum et est occaecati\n",
            "Title : nesciunt quas odio\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "response = requests.get(\"https://jsonplaceholder.typicode.com/posts\")\n",
        "\n",
        "posts = response.json()\n",
        "\n",
        "print(f\" No of posts : {len(posts)}\")\n",
        "\n",
        "for i in range(5):\n",
        "  print(f\"Title : {posts[i]['title']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koNE51KrfXhj"
      },
      "source": [
        "### Question 3.3 (Solved): Using Query Parameters\n",
        "\n",
        "The proper way to add query parameters is using the `params` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W6O-Kd4DfXhj",
        "outputId": "191bdd14-5b71-4625-912d-25b5a60c2e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 1 has 10 posts\n",
            "\n",
            "Actual URL used: https://jsonplaceholder.typicode.com/posts?userId=1\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "# Bad way (manual string building)\n",
        "# url = \"https://jsonplaceholder.typicode.com/posts?userId=1\"\n",
        "\n",
        "# Good way (using params)\n",
        "response = requests.get(\n",
        "    \"https://jsonplaceholder.typicode.com/posts\",\n",
        "    params={\"userId\": 1}\n",
        ")\n",
        "\n",
        "posts = response.json()\n",
        "print(f\"User 1 has {len(posts)} posts\")\n",
        "print(f\"\\nActual URL used: {response.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i7M3G7gZk5DA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV9-WDQbfXhj"
      },
      "source": [
        "### Question 3.4: Filter Posts by User\n",
        "\n",
        "Fetch all posts by user 5 and user 7. Compare how many posts each user has.\n",
        "\n",
        "**Hint**: Make two separate requests with different `userId` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FZacMbtDfXhk",
        "outputId": "093eb96a-b5b2-4adf-a994-39965e6b9d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 5 has 10 posts\n",
            "User 7 has 10 posts\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "response_5 = requests.get(\"https://jsonplaceholder.typicode.com/posts\", params = {\"userId\" : 5})\n",
        "response_7 = requests.get(\"https://jsonplaceholder.typicode.com/posts\", params = {\"userId\" : 7})\n",
        "\n",
        "resp_5 = response_5.json()\n",
        "resp_7 = response_7.json()\n",
        "\n",
        "print(f\"User 5 has {len(resp_5)} posts\")\n",
        "print(f\"User 7 has {len(resp_7)} posts\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzixuIbZfXhk"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.2 Working with Real APIs\n",
        "\n",
        "Let's work with some real-world APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GXRQOYDfXhk"
      },
      "source": [
        "### Question 3.5 (Solved): GitHub API - Public Repositories\n",
        "\n",
        "The GitHub API is free to use (with rate limits) and doesn't require authentication for public data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3ooIKHP0fXhl",
        "outputId": "5ba0a52e-db86-4b75-c2ad-db5a44bdfa8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository: pandas-dev/pandas\n",
            "Description: Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more\n",
            "Stars: 47,734\n",
            "Forks: 19,588\n",
            "Language: Python\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "# Fetch information about a popular repository\n",
        "response = requests.get(\n",
        "    \"https://api.github.com/repos/pandas-dev/pandas\",\n",
        "    headers={\"Accept\": \"application/vnd.github.v3+json\"}\n",
        ")\n",
        "\n",
        "if response.ok:\n",
        "    repo = response.json()\n",
        "    print(f\"Repository: {repo['full_name']}\")\n",
        "    print(f\"Description: {repo['description']}\")\n",
        "    print(f\"Stars: {repo['stargazers_count']:,}\")\n",
        "    print(f\"Forks: {repo['forks_count']:,}\")\n",
        "    print(f\"Language: {repo['language']}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubsjif0MfXhl"
      },
      "source": [
        "### Question 3.6: Compare Popular ML Libraries\n",
        "\n",
        "Fetch information about these ML-related repositories and create a comparison table:\n",
        "- `scikit-learn/scikit-learn`\n",
        "- `pytorch/pytorch`\n",
        "- `tensorflow/tensorflow`\n",
        "\n",
        "Show: name, stars, forks, and primary language.\n",
        "\n",
        "**Hint**: Loop through the repos and collect data into a list of dictionaries, then create a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "44z8g4o_fXhl"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for repo in repos:\n",
        "    url = f\"https://api.github.com/repos/{repo}\"\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        headers={\"Accept\": \"application/vnd.github.v3+json\"}\n",
        "    )\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        results.append({\n",
        "            \"name\": data[\"full_name\"],\n",
        "            \"stars\": data[\"stargazers_count\"],\n",
        "            \"forks\": data[\"forks_count\"],\n",
        "            \"language\": data[\"language\"]\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oVwVoewfXhm"
      },
      "source": [
        "### Question 3.7: Search GitHub Repositories\n",
        "\n",
        "Use the GitHub search API to find the top 10 most starred repositories with \"machine learning\" in their description.\n",
        "\n",
        "API endpoint: `https://api.github.com/search/repositories`\n",
        "\n",
        "Parameters:\n",
        "- `q`: search query (e.g., \"machine learning\")\n",
        "- `sort`: \"stars\"\n",
        "- `order`: \"desc\"\n",
        "- `per_page`: 10\n",
        "\n",
        "Print the name and star count of each repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvZ50NqQfXhm"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cevxrB4fXhn"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.3 Error Handling\n",
        "\n",
        "Real-world APIs fail. We need to handle errors gracefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX0Yny9RfXhx"
      },
      "source": [
        "### Question 3.8 (Solved): Handling HTTP Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6e4BKehfXhy"
      },
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "def fetch_with_error_handling(url):\n",
        "    \"\"\"Fetch URL with proper error handling.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()  # Raises exception for 4xx/5xx\n",
        "        return response.json()\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout: Request took too long\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP Error: {e.response.status_code}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "    return None\n",
        "\n",
        "# Test with valid URL\n",
        "print(\"Valid URL:\")\n",
        "data = fetch_with_error_handling(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
        "if data:\n",
        "    print(f\"  Got post: {data['title'][:50]}...\")\n",
        "\n",
        "# Test with invalid URL (404)\n",
        "print(\"\\nInvalid URL (404):\")\n",
        "fetch_with_error_handling(\"https://jsonplaceholder.typicode.com/posts/99999\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laNsEnOpfXhz"
      },
      "source": [
        "### Question 3.9: Robust Fetcher Function\n",
        "\n",
        "Write a function `safe_fetch(url, max_retries=3)` that:\n",
        "\n",
        "1. Attempts to fetch the URL\n",
        "2. If it fails with a 5xx error, retries up to `max_retries` times\n",
        "3. Waits 1 second between retries\n",
        "4. Returns the JSON data if successful, None otherwise\n",
        "\n",
        "Test it with `https://httpbin.org/status/500` (always returns 500) and `https://jsonplaceholder.typicode.com/posts/1` (always works)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iudzyTuDfXhz"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import time\n",
        "\n",
        "def safe_fetch(url, max_retries=3):\n",
        "    \"\"\"Fetch URL with retry logic for server errors.\"\"\"\n",
        "    pass  # Implement this\n",
        "\n",
        "# Test your function\n",
        "# print(\"Testing with working URL:\")\n",
        "# result = safe_fetch(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
        "# print(f\"Result: {result}\")\n",
        "\n",
        "# print(\"\\nTesting with failing URL (500):\")\n",
        "# result = safe_fetch(\"https://httpbin.org/status/500\")\n",
        "# print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8-SBpvGfXh0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: The OMDb Movie API\n",
        "\n",
        "Now let's work with the OMDb API - our main data source for the Netflix project.\n",
        "\n",
        "**Note**: You need an API key from https://www.omdbapi.com/apikey.aspx (free tier available).\n",
        "\n",
        "For this lab, we'll use a demo key that has limited functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4i4ZslgfXh0"
      },
      "outputs": [],
      "source": [
        "# Set your API key here\n",
        "# Get a free key from: https://www.omdbapi.com/apikey.aspx\n",
        "OMDB_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your actual key\n",
        "\n",
        "# For demo purposes, you can try with key \"demo\" but it's very limited\n",
        "# OMDB_API_KEY = \"demo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp2k5NvVfXh1"
      },
      "source": [
        "### Question 4.1 (Solved): Fetch a Single Movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSxPG87jfXh1"
      },
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "def fetch_movie(title, year=None, api_key=OMDB_API_KEY):\n",
        "    \"\"\"Fetch movie data from OMDb API.\"\"\"\n",
        "    params = {\n",
        "        \"apikey\": api_key,\n",
        "        \"t\": title,  # Search by title\n",
        "        \"type\": \"movie\"\n",
        "    }\n",
        "    if year:\n",
        "        params[\"y\"] = year\n",
        "\n",
        "    response = requests.get(\"https://www.omdbapi.com/\", params=params)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        if data.get(\"Response\") == \"True\":\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"Movie not found: {data.get('Error')}\")\n",
        "    return None\n",
        "\n",
        "# Fetch Inception\n",
        "movie = fetch_movie(\"Inception\", 2010)\n",
        "if movie:\n",
        "    print(f\"Title: {movie['Title']}\")\n",
        "    print(f\"Year: {movie['Year']}\")\n",
        "    print(f\"Director: {movie['Director']}\")\n",
        "    print(f\"IMDB Rating: {movie['imdbRating']}\")\n",
        "    print(f\"Genre: {movie['Genre']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueD04dLsfXh1"
      },
      "source": [
        "### Question 4.2: Explore the Response\n",
        "\n",
        "Fetch data for \"The Dark Knight\" and print ALL available fields in the response.\n",
        "\n",
        "Which fields might be useful for predicting movie success?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4O_OD-4fXh2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20QztV4rfXh2"
      },
      "source": [
        "### Question 4.3: Fetch Multiple Movies\n",
        "\n",
        "Create a function `fetch_movies(titles)` that:\n",
        "1. Takes a list of movie titles\n",
        "2. Fetches data for each movie\n",
        "3. Returns a list of movie dictionaries (only successful fetches)\n",
        "4. Adds a 0.5 second delay between requests (to respect rate limits)\n",
        "\n",
        "Test it with: `[\"Inception\", \"The Matrix\", \"Interstellar\", \"NonExistentMovie123\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iheZEoDufXh3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "def fetch_movies(titles):\n",
        "    \"\"\"Fetch multiple movies from OMDb API.\"\"\"\n",
        "    pass  # Implement this\n",
        "\n",
        "# Test\n",
        "# test_titles = [\"Inception\", \"The Matrix\", \"Interstellar\", \"NonExistentMovie123\"]\n",
        "# movies = fetch_movies(test_titles)\n",
        "# print(f\"Successfully fetched {len(movies)} out of {len(test_titles)} movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LrlUz-6fXh3"
      },
      "source": [
        "### Question 4.4: Create a Movie DataFrame\n",
        "\n",
        "Using the movies you fetched, create a pandas DataFrame with these columns:\n",
        "- title\n",
        "- year (as integer)\n",
        "- genre\n",
        "- director\n",
        "- imdb_rating (as float)\n",
        "- imdb_votes (as integer, remove commas)\n",
        "- runtime_minutes (as integer, extract from \"148 min\")\n",
        "- box_office (keep as string for now)\n",
        "\n",
        "**Hint**: You'll need to clean the data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGKLpFh0fXh4"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ougGsQxfXh5"
      },
      "source": [
        "### Question 4.5: Search Movies by Title\n",
        "\n",
        "OMDb also has a search endpoint that returns multiple results.\n",
        "\n",
        "Use the `s` parameter instead of `t` to search for movies containing \"Star Wars\".\n",
        "\n",
        "API endpoint: `https://www.omdbapi.com/?apikey=YOUR_KEY&s=Star Wars&type=movie`\n",
        "\n",
        "Print the title and year of each result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI4oeGEtfXh5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H0PTZzKfXh6"
      },
      "source": [
        "### Question 4.6: Handle Pagination\n",
        "\n",
        "The OMDb search API returns 10 results per page and includes a `totalResults` field.\n",
        "\n",
        "Write a function `search_all_movies(query)` that:\n",
        "1. Searches for movies matching the query\n",
        "2. Fetches ALL pages of results (use the `page` parameter)\n",
        "3. Returns a list of all movies found\n",
        "\n",
        "**Hint**: `totalResults` tells you how many movies exist. Divide by 10 to get the number of pages.\n",
        "\n",
        "Test with a query that has many results like \"Batman\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3XZgaKjfXh6"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "def search_all_movies(query, api_key=OMDB_API_KEY):\n",
        "    \"\"\"Search OMDb and return ALL matching movies across all pages.\"\"\"\n",
        "    pass  # Implement this\n",
        "\n",
        "# Test\n",
        "# all_batman = search_all_movies(\"Batman\")\n",
        "# print(f\"Found {len(all_batman)} Batman movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjkyoFcKfXh7"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Web Scraping with BeautifulSoup\n",
        "\n",
        "When APIs don't exist or don't have what we need, we scrape.\n",
        "\n",
        "## 5.1 HTML Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1tP8SUTfXh8"
      },
      "source": [
        "### Question 5.1 (Solved): Parse HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1beHeoamfXh8"
      },
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "    <div class=\"movie\" id=\"movie-1\">\n",
        "        <h2 class=\"title\">Inception</h2>\n",
        "        <span class=\"year\">2010</span>\n",
        "        <span class=\"rating\">8.8</span>\n",
        "        <a href=\"/movies/inception\">More Info</a>\n",
        "    </div>\n",
        "    <div class=\"movie\" id=\"movie-2\">\n",
        "        <h2 class=\"title\">The Matrix</h2>\n",
        "        <span class=\"year\">1999</span>\n",
        "        <span class=\"rating\">8.7</span>\n",
        "        <a href=\"/movies/matrix\">More Info</a>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Find all movie divs\n",
        "movies = soup.find_all('div', class_='movie')\n",
        "print(f\"Found {len(movies)} movies\\n\")\n",
        "\n",
        "# Extract data from each\n",
        "for movie in movies:\n",
        "    title = movie.find('h2', class_='title').text\n",
        "    year = movie.find('span', class_='year').text\n",
        "    rating = movie.find('span', class_='rating').text\n",
        "    link = movie.find('a')['href']\n",
        "\n",
        "    print(f\"{title} ({year}) - Rating: {rating} - Link: {link}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qR6TfqpfXh9"
      },
      "source": [
        "### Question 5.2: CSS Selectors\n",
        "\n",
        "Rewrite the above extraction using CSS selectors (`.select()` and `.select_one()`) instead of `.find()` and `.find_all()`.\n",
        "\n",
        "**Hint**:\n",
        "- `.movie` selects elements with class \"movie\"\n",
        "- `.movie .title` selects elements with class \"title\" inside class \"movie\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh5kN9iXfXh9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Use the same 'soup' from above\n",
        "\n",
        "# Extract using CSS selectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU0otM86fXh-"
      },
      "source": [
        "### Question 5.3: Scrape a Real Website\n",
        "\n",
        "Let's scrape the example website `http://quotes.toscrape.com/` which is designed for scraping practice.\n",
        "\n",
        "Extract all quotes from the first page, including:\n",
        "- The quote text\n",
        "- The author name\n",
        "- The tags\n",
        "\n",
        "Return the results as a list of dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7-G3x1BfXh_"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Fetch the page\n",
        "url = \"http://quotes.toscrape.com/\"\n",
        "\n",
        "# Parse the HTML\n",
        "\n",
        "# Extract quotes\n",
        "\n",
        "# Print results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcDBDQUmfXh_"
      },
      "source": [
        "### Question 5.4: Handle Pagination in Scraping\n",
        "\n",
        "The quotes website has multiple pages. Scrape the first 3 pages and collect all quotes.\n",
        "\n",
        "Pages follow the pattern:\n",
        "- Page 1: `http://quotes.toscrape.com/page/1/`\n",
        "- Page 2: `http://quotes.toscrape.com/page/2/`\n",
        "- etc.\n",
        "\n",
        "**Remember**: Add a delay between requests to be polite!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_fEpcE2fXh_"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zzSlPZyfXiA"
      },
      "source": [
        "### Question 5.5: Extract Table Data\n",
        "\n",
        "Scrape the table from `https://www.w3schools.com/html/html_tables.asp`.\n",
        "\n",
        "The table contains company data. Extract all rows and create a pandas DataFrame.\n",
        "\n",
        "**Hint**: Look for `<table>`, `<tr>` (table row), `<th>` (header), and `<td>` (data cell) elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1OBjKlCfXiA"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Hint: pandas has a read_html() function that can do this automatically!\n",
        "# But try doing it manually first to understand the process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77IYpyRkfXiA"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 6: Building the Movie Data Pipeline\n",
        "\n",
        "Now let's put everything together to build a complete data collection pipeline for our Netflix project.\n",
        "\n",
        "## 6.1 The Complete Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGL2rV9RfXiB"
      },
      "source": [
        "### Question 6.1 (Solved): Movie Data Collector Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwE3nZz3fXiB"
      },
      "outputs": [],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "class MovieDataCollector:\n",
        "    \"\"\"Collect movie data from OMDb API.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"http://www.omdbapi.com/\"\n",
        "        self.delay = 0.5  # Seconds between requests\n",
        "\n",
        "    def fetch_movie(self, title: str, year: Optional[int] = None) -> Optional[Dict]:\n",
        "        \"\"\"Fetch a single movie by title.\"\"\"\n",
        "        params = {\n",
        "            \"apikey\": self.api_key,\n",
        "            \"t\": title,\n",
        "            \"type\": \"movie\"\n",
        "        }\n",
        "        if year:\n",
        "            params[\"y\"] = year\n",
        "\n",
        "        try:\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if data.get(\"Response\") == \"True\":\n",
        "                return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {title}: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fetch_movies(self, titles: List[str]) -> List[Dict]:\n",
        "        \"\"\"Fetch multiple movies.\"\"\"\n",
        "        movies = []\n",
        "\n",
        "        for i, title in enumerate(titles):\n",
        "            print(f\"Fetching {i+1}/{len(titles)}: {title}\")\n",
        "            movie = self.fetch_movie(title)\n",
        "\n",
        "            if movie:\n",
        "                movies.append(movie)\n",
        "\n",
        "            time.sleep(self.delay)\n",
        "\n",
        "        return movies\n",
        "\n",
        "    def to_dataframe(self, movies: List[Dict]) -> pd.DataFrame:\n",
        "        \"\"\"Convert movie data to cleaned DataFrame.\"\"\"\n",
        "        if not movies:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Extract relevant fields\n",
        "        rows = []\n",
        "        for m in movies:\n",
        "            rows.append({\n",
        "                \"title\": m.get(\"Title\"),\n",
        "                \"year\": m.get(\"Year\"),\n",
        "                \"genre\": m.get(\"Genre\"),\n",
        "                \"director\": m.get(\"Director\"),\n",
        "                \"actors\": m.get(\"Actors\"),\n",
        "                \"imdb_rating\": m.get(\"imdbRating\"),\n",
        "                \"imdb_votes\": m.get(\"imdbVotes\"),\n",
        "                \"runtime\": m.get(\"Runtime\"),\n",
        "                \"box_office\": m.get(\"BoxOffice\"),\n",
        "                \"imdb_id\": m.get(\"imdbID\")\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "\n",
        "        # Clean data types\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "        df[\"imdb_rating\"] = pd.to_numeric(df[\"imdb_rating\"], errors=\"coerce\")\n",
        "        df[\"imdb_votes\"] = df[\"imdb_votes\"].str.replace(\",\", \"\").pipe(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
        "        # Fix: str.extract returns a DataFrame, we need column 0 to get a Series\n",
        "        df[\"runtime_min\"] = df[\"runtime\"].str.extract(r\"(\\d+)\")[0].pipe(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "        return df\n",
        "\n",
        "# Usage example\n",
        "# collector = MovieDataCollector(OMDB_API_KEY)\n",
        "# movies = collector.fetch_movies([\"Inception\", \"The Matrix\"])\n",
        "# df = collector.to_dataframe(movies)\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaidQRnTfXiD"
      },
      "source": [
        "### Question 6.2: Add Search Functionality\n",
        "\n",
        "Extend the `MovieDataCollector` class to add a `search_movies(query, max_results=50)` method that:\n",
        "1. Searches for movies matching the query\n",
        "2. Handles pagination to get up to `max_results` movies\n",
        "3. For each search result, fetches the full movie details\n",
        "4. Returns the detailed movie data\n",
        "\n",
        "**Hint**: Search results only contain basic info (title, year, poster, imdbID). You need to use the imdbID to fetch full details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JNst9AWfXiD"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Extend the MovieDataCollector class or add a method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fWngtO-fXiD"
      },
      "source": [
        "### Question 6.3: Build a Genre-Based Dataset\n",
        "\n",
        "Use your collector to build a dataset of popular movies from different genres:\n",
        "\n",
        "1. Search for 10 movies each for: \"action\", \"comedy\", \"drama\", \"horror\", \"sci-fi\"\n",
        "2. Combine all results into a single DataFrame\n",
        "3. Remove any duplicates (some movies might appear in multiple searches)\n",
        "4. Save to CSV\n",
        "\n",
        "**Note**: This might take a while due to rate limiting. Start with fewer movies for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZyC4C8fXiD"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6EcP-DsfXiE"
      },
      "source": [
        "### Question 6.4: Data Quality Analysis\n",
        "\n",
        "Using the dataset you created:\n",
        "\n",
        "1. How many movies have missing IMDB ratings?\n",
        "2. How many movies have missing box office data?\n",
        "3. What's the distribution of ratings? (min, max, mean, median)\n",
        "4. Which directors appear most frequently?\n",
        "5. What's the average runtime by genre?\n",
        "\n",
        "These quality checks will be important for Week 2 (Data Validation)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-3HtOM3fXiE"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjiuR8iLfXiG"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 7: Challenge Problems\n",
        "\n",
        "These are optional advanced exercises for those who finish early."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQXTMTNbfXiH"
      },
      "source": [
        "### Challenge 7.1: Rate Limit Handler\n",
        "\n",
        "Create a `RateLimiter` class that:\n",
        "1. Tracks how many requests have been made\n",
        "2. Automatically adds delays to stay under a rate limit\n",
        "3. Handles 429 (Too Many Requests) responses by waiting and retrying\n",
        "\n",
        "```python\n",
        "limiter = RateLimiter(requests_per_minute=30)\n",
        "response = limiter.get(\"https://api.example.com/data\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23fymA20fXiH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEYk6cRSfXiI"
      },
      "source": [
        "### Challenge 7.2: Async Movie Collector\n",
        "\n",
        "The synchronous approach is slow because we wait for each request to complete.\n",
        "\n",
        "Create an async version using `aiohttp` that can fetch multiple movies concurrently (while still respecting rate limits).\n",
        "\n",
        "Compare the time to fetch 20 movies with sync vs async approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELYqjK6YfXiJ"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Hint: You'll need to install aiohttp: pip install aiohttp\n",
        "# And use asyncio to run the async code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL_MrIurfXiJ"
      },
      "source": [
        "### Challenge 7.3: Multi-Source Data Fusion\n",
        "\n",
        "Create a data collection pipeline that:\n",
        "1. Fetches basic movie data from OMDb\n",
        "2. Enriches it with additional data from another source (e.g., Wikipedia API for plot summaries)\n",
        "3. Merges the data based on movie title/year\n",
        "4. Handles cases where data is missing from one source\n",
        "\n",
        "Wikipedia API example:\n",
        "```\n",
        "https://en.wikipedia.org/api/rest_v1/page/summary/Inception_(film)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh9V4bfOfXiK"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwb0dP6IfXiK"
      },
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "In this lab, you learned:\n",
        "\n",
        "1. **HTTP Fundamentals**: URLs, status codes, headers\n",
        "2. **curl**: Command-line HTTP requests\n",
        "3. **Python requests**: Programmatic data collection\n",
        "4. **Error handling**: Timeouts, retries, status codes\n",
        "5. **OMDb API**: Real-world movie data\n",
        "6. **BeautifulSoup**: Web scraping when APIs don't exist\n",
        "7. **Data pipelines**: Building reusable collection code\n",
        "\n",
        "## Next Week\n",
        "\n",
        "**Week 2: Data Validation & Quality**\n",
        "\n",
        "The data we collected today is messy! Next week we'll learn:\n",
        "- Schema validation with Pydantic\n",
        "- Data type cleaning\n",
        "- Handling missing values\n",
        "- Quality metrics\n",
        "\n",
        "---\n",
        "\n",
        "## Submission\n",
        "\n",
        "Save your completed notebook and submit:\n",
        "1. This notebook with all cells executed\n",
        "2. The CSV file of movies you collected\n",
        "3. A brief summary (1 paragraph) of what you learned"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}